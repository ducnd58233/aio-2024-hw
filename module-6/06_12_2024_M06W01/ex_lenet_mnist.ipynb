{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as numpy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = './data'\n",
    "train_data = datasets.MNIST(\n",
    "    root=ROOT,\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=ROOT,\n",
    "    train=False,\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training : validation = 0.9 : 0.1\n",
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(\n",
    "    train_data,\n",
    "    [n_train_examples, n_valid_examples]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean and std for normalization\n",
    "mean = train_data.dataset.data.float().mean() / 255\n",
    "std = train_data.dataset.data.float().std() / 255\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[mean], std=[std])\n",
    "])\n",
    "\n",
    "train_data.dataset.transform = train_transforms\n",
    "valid_data.dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_data,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "valid_dataloader = data.DataLoader(\n",
    "    valid_data,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mô hình LeNet](public/images/lenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=6, kernel_size=5, padding='same'\n",
    "        )\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc_2 = nn.Linear(120, 84)\n",
    "        self.fc_3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.avgpool1(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "        outputs = self.avgpool2(outputs)\n",
    "        outputs = F.relu(outputs)\n",
    "        outputs = self.flatten(outputs)\n",
    "        outputs = self.fc_1(outputs)\n",
    "        outputs = self.fc_2(outputs)\n",
    "        outputs = self.fc_3(outputs)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    device,\n",
    "    epoch=0,\n",
    "    log_interval=50,\n",
    "):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "        total_count += labels.size(0)\n",
    "\n",
    "        if idx & log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {idx:5d}/{len(train_dataloader):5d} batches {elapsed:8.3f} sec\"\n",
    "                f\"| accuracy {total_acc / total_count:8.3f}\"\n",
    "            )\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss\n",
    "\n",
    "def evaluate(model, criterion, valid_dataloader, device):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, labels) in enumerate(valid_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            loss = criterion(predictions, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "            total_count += labels.size(0)\n",
    "\n",
    "    epoch_acc = total_acc / total_count\n",
    "    epoch_loss = sum(losses) / len(losses)\n",
    "    return epoch_acc, epoch_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |     1/  211 batches    0.330 sec| accuracy    0.092\n",
      "| epoch   1 |     4/  211 batches    0.126 sec| accuracy    0.292\n",
      "| epoch   1 |     5/  211 batches    0.046 sec| accuracy    0.328\n",
      "| epoch   1 |     8/  211 batches    0.126 sec| accuracy    0.471\n",
      "| epoch   1 |     9/  211 batches    0.043 sec| accuracy    0.594\n",
      "| epoch   1 |    12/  211 batches    0.122 sec| accuracy    0.634\n",
      "| epoch   1 |    13/  211 batches    0.042 sec| accuracy    0.660\n",
      "| epoch   1 |    64/  211 batches    2.069 sec| accuracy    0.786\n",
      "| epoch   1 |    65/  211 batches    0.040 sec| accuracy    0.859\n",
      "| epoch   1 |    68/  211 batches    0.121 sec| accuracy    0.879\n",
      "| epoch   1 |    69/  211 batches    0.040 sec| accuracy    0.879\n",
      "| epoch   1 |    72/  211 batches    0.123 sec| accuracy    0.871\n",
      "| epoch   1 |    73/  211 batches    0.041 sec| accuracy    0.883\n",
      "| epoch   1 |    76/  211 batches    0.123 sec| accuracy    0.901\n",
      "| epoch   1 |    77/  211 batches    0.040 sec| accuracy    0.859\n",
      "| epoch   1 |   128/  211 batches    2.042 sec| accuracy    0.895\n",
      "| epoch   1 |   129/  211 batches    0.041 sec| accuracy    0.910\n",
      "| epoch   1 |   132/  211 batches    0.121 sec| accuracy    0.914\n",
      "| epoch   1 |   133/  211 batches    0.040 sec| accuracy    0.910\n",
      "| epoch   1 |   136/  211 batches    0.124 sec| accuracy    0.913\n",
      "| epoch   1 |   137/  211 batches    0.041 sec| accuracy    0.949\n",
      "| epoch   1 |   140/  211 batches    0.123 sec| accuracy    0.928\n",
      "| epoch   1 |   141/  211 batches    0.041 sec| accuracy    0.895\n",
      "| epoch   1 |   192/  211 batches    2.057 sec| accuracy    0.927\n",
      "| epoch   1 |   193/  211 batches    0.041 sec| accuracy    0.945\n",
      "| epoch   1 |   196/  211 batches    0.120 sec| accuracy    0.931\n",
      "| epoch   1 |   197/  211 batches    0.041 sec| accuracy    0.961\n",
      "| epoch   1 |   200/  211 batches    0.122 sec| accuracy    0.936\n",
      "| epoch   1 |   201/  211 batches    0.041 sec| accuracy    0.961\n",
      "| epoch   1 |   204/  211 batches    0.123 sec| accuracy    0.947\n",
      "| epoch   1 |   205/  211 batches    0.040 sec| accuracy    0.938\n",
      "------------------------------------------------------------\n",
      "| End of epoch   1 | Time:9.692053079605103s | Train Accuracy    0.939 | Train Loss    0.530 | Valid Accuracy    0.942 | Valid Loss    0.194\n",
      "------------------------------------------------------------\n",
      "| epoch   2 |     1/  211 batches    0.091 sec| accuracy    0.949\n",
      "| epoch   2 |     4/  211 batches    0.135 sec| accuracy    0.941\n",
      "| epoch   2 |     5/  211 batches    0.044 sec| accuracy    0.953\n",
      "| epoch   2 |     8/  211 batches    0.125 sec| accuracy    0.938\n",
      "| epoch   2 |     9/  211 batches    0.040 sec| accuracy    0.945\n",
      "| epoch   2 |    12/  211 batches    0.119 sec| accuracy    0.940\n",
      "| epoch   2 |    13/  211 batches    0.040 sec| accuracy    0.941\n",
      "| epoch   2 |    64/  211 batches    2.069 sec| accuracy    0.956\n",
      "| epoch   2 |    65/  211 batches    0.041 sec| accuracy    0.941\n",
      "| epoch   2 |    68/  211 batches    0.125 sec| accuracy    0.956\n",
      "| epoch   2 |    69/  211 batches    0.049 sec| accuracy    0.961\n",
      "| epoch   2 |    72/  211 batches    0.122 sec| accuracy    0.949\n",
      "| epoch   2 |    73/  211 batches    0.041 sec| accuracy    0.949\n",
      "| epoch   2 |    76/  211 batches    0.127 sec| accuracy    0.953\n",
      "| epoch   2 |    77/  211 batches    0.041 sec| accuracy    0.969\n",
      "| epoch   2 |   128/  211 batches    2.071 sec| accuracy    0.962\n",
      "| epoch   2 |   129/  211 batches    0.040 sec| accuracy    0.965\n",
      "| epoch   2 |   132/  211 batches    0.121 sec| accuracy    0.975\n",
      "| epoch   2 |   133/  211 batches    0.040 sec| accuracy    0.961\n",
      "| epoch   2 |   136/  211 batches    0.122 sec| accuracy    0.957\n",
      "| epoch   2 |   137/  211 batches    0.040 sec| accuracy    0.961\n",
      "| epoch   2 |   140/  211 batches    0.122 sec| accuracy    0.966\n",
      "| epoch   2 |   141/  211 batches    0.041 sec| accuracy    0.973\n",
      "| epoch   2 |   192/  211 batches    2.100 sec| accuracy    0.965\n",
      "| epoch   2 |   193/  211 batches    0.042 sec| accuracy    0.945\n",
      "| epoch   2 |   196/  211 batches    0.128 sec| accuracy    0.977\n",
      "| epoch   2 |   197/  211 batches    0.042 sec| accuracy    0.961\n",
      "| epoch   2 |   200/  211 batches    0.124 sec| accuracy    0.969\n",
      "| epoch   2 |   201/  211 batches    0.041 sec| accuracy    0.969\n",
      "| epoch   2 |   204/  211 batches    0.127 sec| accuracy    0.970\n",
      "| epoch   2 |   205/  211 batches    0.041 sec| accuracy    0.965\n",
      "------------------------------------------------------------\n",
      "| End of epoch   2 | Time:9.581913948059082s | Train Accuracy    0.969 | Train Loss    0.128 | Valid Accuracy    0.970 | Valid Loss    0.104\n",
      "------------------------------------------------------------\n",
      "| epoch   3 |     1/  211 batches    0.098 sec| accuracy    0.965\n",
      "| epoch   3 |     4/  211 batches    0.140 sec| accuracy    0.964\n",
      "| epoch   3 |     5/  211 batches    0.042 sec| accuracy    0.988\n",
      "| epoch   3 |     8/  211 batches    0.128 sec| accuracy    0.980\n",
      "| epoch   3 |     9/  211 batches    0.042 sec| accuracy    0.965\n",
      "| epoch   3 |    12/  211 batches    0.132 sec| accuracy    0.969\n",
      "| epoch   3 |    13/  211 batches    0.070 sec| accuracy    0.969\n",
      "| epoch   3 |    64/  211 batches    2.055 sec| accuracy    0.970\n",
      "| epoch   3 |    65/  211 batches    0.040 sec| accuracy    0.977\n",
      "| epoch   3 |    68/  211 batches    0.118 sec| accuracy    0.966\n",
      "| epoch   3 |    69/  211 batches    0.039 sec| accuracy    0.965\n",
      "| epoch   3 |    72/  211 batches    0.119 sec| accuracy    0.978\n",
      "| epoch   3 |    73/  211 batches    0.040 sec| accuracy    0.980\n",
      "| epoch   3 |    76/  211 batches    0.122 sec| accuracy    0.971\n",
      "| epoch   3 |    77/  211 batches    0.040 sec| accuracy    0.945\n",
      "| epoch   3 |   128/  211 batches    2.061 sec| accuracy    0.973\n",
      "| epoch   3 |   129/  211 batches    0.041 sec| accuracy    0.969\n",
      "| epoch   3 |   132/  211 batches    0.121 sec| accuracy    0.970\n",
      "| epoch   3 |   133/  211 batches    0.040 sec| accuracy    0.953\n",
      "| epoch   3 |   136/  211 batches    0.119 sec| accuracy    0.966\n",
      "| epoch   3 |   137/  211 batches    0.041 sec| accuracy    0.980\n",
      "| epoch   3 |   140/  211 batches    0.117 sec| accuracy    0.979\n",
      "| epoch   3 |   141/  211 batches    0.039 sec| accuracy    0.961\n",
      "| epoch   3 |   192/  211 batches    2.046 sec| accuracy    0.977\n",
      "| epoch   3 |   193/  211 batches    0.039 sec| accuracy    0.980\n",
      "| epoch   3 |   196/  211 batches    0.118 sec| accuracy    0.962\n",
      "| epoch   3 |   197/  211 batches    0.039 sec| accuracy    0.984\n",
      "| epoch   3 |   200/  211 batches    0.119 sec| accuracy    0.969\n",
      "| epoch   3 |   201/  211 batches    0.039 sec| accuracy    0.969\n",
      "| epoch   3 |   204/  211 batches    0.121 sec| accuracy    0.973\n",
      "| epoch   3 |   205/  211 batches    0.039 sec| accuracy    0.980\n",
      "------------------------------------------------------------\n",
      "| End of epoch   3 | Time:9.512153387069702s | Train Accuracy    0.970 | Train Loss    0.089 | Valid Accuracy    0.972 | Valid Loss    0.096\n",
      "------------------------------------------------------------\n",
      "| epoch   4 |     1/  211 batches    0.094 sec| accuracy    0.979\n",
      "| epoch   4 |     4/  211 batches    0.125 sec| accuracy    0.965\n",
      "| epoch   4 |     5/  211 batches    0.041 sec| accuracy    0.988\n",
      "| epoch   4 |     8/  211 batches    0.119 sec| accuracy    0.973\n",
      "| epoch   4 |     9/  211 batches    0.040 sec| accuracy    0.969\n",
      "| epoch   4 |    12/  211 batches    0.119 sec| accuracy    0.979\n",
      "| epoch   4 |    13/  211 batches    0.041 sec| accuracy    0.973\n",
      "| epoch   4 |    64/  211 batches    2.071 sec| accuracy    0.977\n",
      "| epoch   4 |    65/  211 batches    0.039 sec| accuracy    0.992\n",
      "| epoch   4 |    68/  211 batches    0.119 sec| accuracy    0.977\n",
      "| epoch   4 |    69/  211 batches    0.040 sec| accuracy    0.977\n",
      "| epoch   4 |    72/  211 batches    0.119 sec| accuracy    0.969\n",
      "| epoch   4 |    73/  211 batches    0.039 sec| accuracy    0.977\n",
      "| epoch   4 |    76/  211 batches    0.117 sec| accuracy    0.990\n",
      "| epoch   4 |    77/  211 batches    0.039 sec| accuracy    0.984\n",
      "| epoch   4 |   128/  211 batches    2.023 sec| accuracy    0.974\n",
      "| epoch   4 |   129/  211 batches    0.040 sec| accuracy    0.973\n",
      "| epoch   4 |   132/  211 batches    0.117 sec| accuracy    0.971\n",
      "| epoch   4 |   133/  211 batches    0.039 sec| accuracy    0.973\n",
      "| epoch   4 |   136/  211 batches    0.120 sec| accuracy    0.990\n",
      "| epoch   4 |   137/  211 batches    0.041 sec| accuracy    0.973\n",
      "| epoch   4 |   140/  211 batches    0.123 sec| accuracy    0.979\n",
      "| epoch   4 |   141/  211 batches    0.041 sec| accuracy    0.965\n",
      "| epoch   4 |   192/  211 batches    2.110 sec| accuracy    0.978\n",
      "| epoch   4 |   193/  211 batches    0.042 sec| accuracy    0.977\n",
      "| epoch   4 |   196/  211 batches    0.125 sec| accuracy    0.975\n",
      "| epoch   4 |   197/  211 batches    0.056 sec| accuracy    0.965\n",
      "| epoch   4 |   200/  211 batches    0.144 sec| accuracy    0.984\n",
      "| epoch   4 |   201/  211 batches    0.043 sec| accuracy    0.992\n",
      "| epoch   4 |   204/  211 batches    0.131 sec| accuracy    0.977\n",
      "| epoch   4 |   205/  211 batches    0.040 sec| accuracy    0.992\n",
      "------------------------------------------------------------\n",
      "| End of epoch   4 | Time:9.500082015991211s | Train Accuracy    0.977 | Train Loss    0.074 | Valid Accuracy    0.979 | Valid Loss    0.072\n",
      "------------------------------------------------------------\n",
      "| epoch   5 |     1/  211 batches    0.095 sec| accuracy    0.975\n",
      "| epoch   5 |     4/  211 batches    0.145 sec| accuracy    0.974\n",
      "| epoch   5 |     5/  211 batches    0.043 sec| accuracy    0.988\n",
      "| epoch   5 |     8/  211 batches    0.123 sec| accuracy    0.969\n",
      "| epoch   5 |     9/  211 batches    0.042 sec| accuracy    0.988\n",
      "| epoch   5 |    12/  211 batches    0.125 sec| accuracy    0.983\n",
      "| epoch   5 |    13/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   5 |    64/  211 batches    2.119 sec| accuracy    0.981\n",
      "| epoch   5 |    65/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   5 |    68/  211 batches    0.126 sec| accuracy    0.984\n",
      "| epoch   5 |    69/  211 batches    0.044 sec| accuracy    0.980\n",
      "| epoch   5 |    72/  211 batches    0.124 sec| accuracy    0.984\n",
      "| epoch   5 |    73/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   5 |    76/  211 batches    0.123 sec| accuracy    0.983\n",
      "| epoch   5 |    77/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   5 |   128/  211 batches    2.126 sec| accuracy    0.980\n",
      "| epoch   5 |   129/  211 batches    0.043 sec| accuracy    0.980\n",
      "| epoch   5 |   132/  211 batches    0.123 sec| accuracy    0.988\n",
      "| epoch   5 |   133/  211 batches    0.043 sec| accuracy    0.988\n",
      "| epoch   5 |   136/  211 batches    0.125 sec| accuracy    0.983\n",
      "| epoch   5 |   137/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   5 |   140/  211 batches    0.125 sec| accuracy    0.973\n",
      "| epoch   5 |   141/  211 batches    0.041 sec| accuracy    0.973\n",
      "| epoch   5 |   192/  211 batches    2.101 sec| accuracy    0.981\n",
      "| epoch   5 |   193/  211 batches    0.043 sec| accuracy    0.980\n",
      "| epoch   5 |   196/  211 batches    0.124 sec| accuracy    0.982\n",
      "| epoch   5 |   197/  211 batches    0.042 sec| accuracy    0.980\n",
      "| epoch   5 |   200/  211 batches    0.125 sec| accuracy    0.979\n",
      "| epoch   5 |   201/  211 batches    0.041 sec| accuracy    0.973\n",
      "| epoch   5 |   204/  211 batches    0.122 sec| accuracy    0.983\n",
      "| epoch   5 |   205/  211 batches    0.041 sec| accuracy    0.977\n",
      "------------------------------------------------------------\n",
      "| End of epoch   5 | Time:9.704607963562012s | Train Accuracy    0.979 | Train Loss    0.061 | Valid Accuracy    0.981 | Valid Loss    0.066\n",
      "------------------------------------------------------------\n",
      "| epoch   6 |     1/  211 batches    0.092 sec| accuracy    0.977\n",
      "| epoch   6 |     4/  211 batches    0.141 sec| accuracy    0.982\n",
      "| epoch   6 |     5/  211 batches    0.043 sec| accuracy    0.992\n",
      "| epoch   6 |     8/  211 batches    0.124 sec| accuracy    0.990\n",
      "| epoch   6 |     9/  211 batches    0.042 sec| accuracy    0.988\n",
      "| epoch   6 |    12/  211 batches    0.125 sec| accuracy    0.984\n",
      "| epoch   6 |    13/  211 batches    0.041 sec| accuracy    0.992\n",
      "| epoch   6 |    64/  211 batches    2.097 sec| accuracy    0.984\n",
      "| epoch   6 |    65/  211 batches    0.041 sec| accuracy    0.980\n",
      "| epoch   6 |    68/  211 batches    0.124 sec| accuracy    0.987\n",
      "| epoch   6 |    69/  211 batches    0.042 sec| accuracy    0.977\n",
      "| epoch   6 |    72/  211 batches    0.125 sec| accuracy    0.979\n",
      "| epoch   6 |    73/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   6 |    76/  211 batches    0.123 sec| accuracy    0.974\n",
      "| epoch   6 |    77/  211 batches    0.041 sec| accuracy    0.992\n",
      "| epoch   6 |   128/  211 batches    2.098 sec| accuracy    0.981\n",
      "| epoch   6 |   129/  211 batches    0.043 sec| accuracy    0.980\n",
      "| epoch   6 |   132/  211 batches    0.125 sec| accuracy    0.986\n",
      "| epoch   6 |   133/  211 batches    0.042 sec| accuracy    0.992\n",
      "| epoch   6 |   136/  211 batches    0.125 sec| accuracy    0.986\n",
      "| epoch   6 |   137/  211 batches    0.040 sec| accuracy    0.988\n",
      "| epoch   6 |   140/  211 batches    0.135 sec| accuracy    0.988\n",
      "| epoch   6 |   141/  211 batches    0.043 sec| accuracy    0.977\n",
      "| epoch   6 |   192/  211 batches    2.141 sec| accuracy    0.982\n",
      "| epoch   6 |   193/  211 batches    0.042 sec| accuracy    0.980\n",
      "| epoch   6 |   196/  211 batches    0.124 sec| accuracy    0.986\n",
      "| epoch   6 |   197/  211 batches    0.042 sec| accuracy    0.980\n",
      "| epoch   6 |   200/  211 batches    0.130 sec| accuracy    0.986\n",
      "| epoch   6 |   201/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   6 |   204/  211 batches    0.129 sec| accuracy    0.984\n",
      "| epoch   6 |   205/  211 batches    0.043 sec| accuracy    0.973\n",
      "------------------------------------------------------------\n",
      "| End of epoch   6 | Time:9.744328260421753s | Train Accuracy    0.983 | Train Loss    0.055 | Valid Accuracy    0.981 | Valid Loss    0.069\n",
      "------------------------------------------------------------\n",
      "| epoch   7 |     1/  211 batches    0.104 sec| accuracy    0.980\n",
      "| epoch   7 |     4/  211 batches    0.142 sec| accuracy    0.987\n",
      "| epoch   7 |     5/  211 batches    0.049 sec| accuracy    0.988\n",
      "| epoch   7 |     8/  211 batches    0.124 sec| accuracy    0.995\n",
      "| epoch   7 |     9/  211 batches    0.043 sec| accuracy    0.988\n",
      "| epoch   7 |    12/  211 batches    0.127 sec| accuracy    0.983\n",
      "| epoch   7 |    13/  211 batches    0.041 sec| accuracy    0.988\n",
      "| epoch   7 |    64/  211 batches    2.140 sec| accuracy    0.984\n",
      "| epoch   7 |    65/  211 batches    0.048 sec| accuracy    0.992\n",
      "| epoch   7 |    68/  211 batches    0.131 sec| accuracy    0.978\n",
      "| epoch   7 |    69/  211 batches    0.044 sec| accuracy    1.000\n",
      "| epoch   7 |    72/  211 batches    0.126 sec| accuracy    0.991\n",
      "| epoch   7 |    73/  211 batches    0.040 sec| accuracy    0.988\n",
      "| epoch   7 |    76/  211 batches    0.124 sec| accuracy    0.987\n",
      "| epoch   7 |    77/  211 batches    0.041 sec| accuracy    0.980\n",
      "| epoch   7 |   128/  211 batches    2.160 sec| accuracy    0.986\n",
      "| epoch   7 |   129/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   7 |   132/  211 batches    0.126 sec| accuracy    0.980\n",
      "| epoch   7 |   133/  211 batches    0.040 sec| accuracy    0.980\n",
      "| epoch   7 |   136/  211 batches    0.124 sec| accuracy    0.980\n",
      "| epoch   7 |   137/  211 batches    0.040 sec| accuracy    0.980\n",
      "| epoch   7 |   140/  211 batches    0.122 sec| accuracy    0.982\n",
      "| epoch   7 |   141/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   7 |   192/  211 batches    2.135 sec| accuracy    0.983\n",
      "| epoch   7 |   193/  211 batches    0.041 sec| accuracy    0.984\n",
      "| epoch   7 |   196/  211 batches    0.125 sec| accuracy    0.984\n",
      "| epoch   7 |   197/  211 batches    0.046 sec| accuracy    0.984\n",
      "| epoch   7 |   200/  211 batches    0.130 sec| accuracy    0.990\n",
      "| epoch   7 |   201/  211 batches    0.041 sec| accuracy    0.980\n",
      "| epoch   7 |   204/  211 batches    0.128 sec| accuracy    0.983\n",
      "| epoch   7 |   205/  211 batches    0.041 sec| accuracy    0.984\n",
      "------------------------------------------------------------\n",
      "| End of epoch   7 | Time:9.8700110912323s | Train Accuracy    0.980 | Train Loss    0.049 | Valid Accuracy    0.980 | Valid Loss    0.070\n",
      "------------------------------------------------------------\n",
      "| epoch   8 |     1/  211 batches    0.093 sec| accuracy    0.984\n",
      "| epoch   8 |     4/  211 batches    0.143 sec| accuracy    0.988\n",
      "| epoch   8 |     5/  211 batches    0.046 sec| accuracy    0.996\n",
      "| epoch   8 |     8/  211 batches    0.130 sec| accuracy    0.984\n",
      "| epoch   8 |     9/  211 batches    0.043 sec| accuracy    0.996\n",
      "| epoch   8 |    12/  211 batches    0.131 sec| accuracy    0.975\n",
      "| epoch   8 |    13/  211 batches    0.043 sec| accuracy    0.984\n",
      "| epoch   8 |    64/  211 batches    2.186 sec| accuracy    0.987\n",
      "| epoch   8 |    65/  211 batches    0.042 sec| accuracy    0.984\n",
      "| epoch   8 |    68/  211 batches    0.127 sec| accuracy    0.990\n",
      "| epoch   8 |    69/  211 batches    0.042 sec| accuracy    0.980\n",
      "| epoch   8 |    72/  211 batches    0.130 sec| accuracy    0.980\n",
      "| epoch   8 |    73/  211 batches    0.042 sec| accuracy    0.984\n",
      "| epoch   8 |    76/  211 batches    0.130 sec| accuracy    0.984\n",
      "| epoch   8 |    77/  211 batches    0.042 sec| accuracy    0.984\n",
      "| epoch   8 |   128/  211 batches    2.162 sec| accuracy    0.986\n",
      "| epoch   8 |   129/  211 batches    0.042 sec| accuracy    0.992\n",
      "| epoch   8 |   132/  211 batches    0.131 sec| accuracy    0.988\n",
      "| epoch   8 |   133/  211 batches    0.042 sec| accuracy    0.984\n",
      "| epoch   8 |   136/  211 batches    0.125 sec| accuracy    0.970\n",
      "| epoch   8 |   137/  211 batches    0.041 sec| accuracy    0.992\n",
      "| epoch   8 |   140/  211 batches    0.124 sec| accuracy    0.987\n",
      "| epoch   8 |   141/  211 batches    0.042 sec| accuracy    0.988\n",
      "| epoch   8 |   192/  211 batches    2.120 sec| accuracy    0.984\n",
      "| epoch   8 |   193/  211 batches    0.046 sec| accuracy    0.984\n",
      "| epoch   8 |   196/  211 batches    0.143 sec| accuracy    0.980\n",
      "| epoch   8 |   197/  211 batches    0.046 sec| accuracy    0.996\n",
      "| epoch   8 |   200/  211 batches    0.130 sec| accuracy    0.986\n",
      "| epoch   8 |   201/  211 batches    0.043 sec| accuracy    0.980\n",
      "| epoch   8 |   204/  211 batches    0.130 sec| accuracy    0.990\n",
      "| epoch   8 |   205/  211 batches    0.043 sec| accuracy    0.973\n",
      "------------------------------------------------------------\n",
      "| End of epoch   8 | Time:9.949500560760498s | Train Accuracy    0.987 | Train Loss    0.045 | Valid Accuracy    0.982 | Valid Loss    0.061\n",
      "------------------------------------------------------------\n",
      "| epoch   9 |     1/  211 batches    0.094 sec| accuracy    0.990\n",
      "| epoch   9 |     4/  211 batches    0.142 sec| accuracy    0.988\n",
      "| epoch   9 |     5/  211 batches    0.045 sec| accuracy    0.992\n",
      "| epoch   9 |     8/  211 batches    0.136 sec| accuracy    0.993\n",
      "| epoch   9 |     9/  211 batches    0.045 sec| accuracy    0.996\n",
      "| epoch   9 |    12/  211 batches    0.133 sec| accuracy    0.990\n",
      "| epoch   9 |    13/  211 batches    0.043 sec| accuracy    0.988\n",
      "| epoch   9 |    64/  211 batches    2.218 sec| accuracy    0.986\n",
      "| epoch   9 |    65/  211 batches    0.042 sec| accuracy    0.988\n",
      "| epoch   9 |    68/  211 batches    0.128 sec| accuracy    0.983\n",
      "| epoch   9 |    69/  211 batches    0.043 sec| accuracy    0.988\n",
      "| epoch   9 |    72/  211 batches    0.131 sec| accuracy    0.980\n",
      "| epoch   9 |    73/  211 batches    0.043 sec| accuracy    0.988\n",
      "| epoch   9 |    76/  211 batches    0.131 sec| accuracy    0.990\n",
      "| epoch   9 |    77/  211 batches    0.044 sec| accuracy    0.996\n",
      "| epoch   9 |   128/  211 batches    2.202 sec| accuracy    0.987\n",
      "| epoch   9 |   129/  211 batches    0.043 sec| accuracy    0.992\n",
      "| epoch   9 |   132/  211 batches    0.127 sec| accuracy    0.983\n",
      "| epoch   9 |   133/  211 batches    0.044 sec| accuracy    0.984\n",
      "| epoch   9 |   136/  211 batches    0.130 sec| accuracy    0.983\n",
      "| epoch   9 |   137/  211 batches    0.042 sec| accuracy    0.973\n",
      "| epoch   9 |   140/  211 batches    0.128 sec| accuracy    0.988\n",
      "| epoch   9 |   141/  211 batches    0.043 sec| accuracy    0.984\n",
      "| epoch   9 |   192/  211 batches    2.202 sec| accuracy    0.987\n",
      "| epoch   9 |   193/  211 batches    0.045 sec| accuracy    0.984\n",
      "| epoch   9 |   196/  211 batches    0.133 sec| accuracy    0.991\n",
      "| epoch   9 |   197/  211 batches    0.046 sec| accuracy    0.980\n",
      "| epoch   9 |   200/  211 batches    0.133 sec| accuracy    0.990\n",
      "| epoch   9 |   201/  211 batches    0.044 sec| accuracy    0.996\n",
      "| epoch   9 |   204/  211 batches    0.129 sec| accuracy    0.991\n",
      "| epoch   9 |   205/  211 batches    0.043 sec| accuracy    0.988\n",
      "------------------------------------------------------------\n",
      "| End of epoch   9 | Time:10.107450485229492s | Train Accuracy    0.986 | Train Loss    0.041 | Valid Accuracy    0.983 | Valid Loss    0.054\n",
      "------------------------------------------------------------\n",
      "| epoch  10 |     1/  211 batches    0.096 sec| accuracy    0.986\n",
      "| epoch  10 |     4/  211 batches    0.146 sec| accuracy    0.988\n",
      "| epoch  10 |     5/  211 batches    0.046 sec| accuracy    0.984\n",
      "| epoch  10 |     8/  211 batches    0.134 sec| accuracy    0.992\n",
      "| epoch  10 |     9/  211 batches    0.047 sec| accuracy    0.988\n",
      "| epoch  10 |    12/  211 batches    0.132 sec| accuracy    0.987\n",
      "| epoch  10 |    13/  211 batches    0.044 sec| accuracy    1.000\n",
      "| epoch  10 |    64/  211 batches    2.240 sec| accuracy    0.990\n",
      "| epoch  10 |    65/  211 batches    0.043 sec| accuracy    0.988\n",
      "| epoch  10 |    68/  211 batches    0.127 sec| accuracy    0.986\n",
      "| epoch  10 |    69/  211 batches    0.045 sec| accuracy    0.977\n",
      "| epoch  10 |    72/  211 batches    0.129 sec| accuracy    0.984\n",
      "| epoch  10 |    73/  211 batches    0.042 sec| accuracy    0.984\n",
      "| epoch  10 |    76/  211 batches    0.129 sec| accuracy    0.984\n",
      "| epoch  10 |    77/  211 batches    0.043 sec| accuracy    0.984\n",
      "| epoch  10 |   128/  211 batches    2.190 sec| accuracy    0.987\n",
      "| epoch  10 |   129/  211 batches    0.043 sec| accuracy    0.992\n",
      "| epoch  10 |   132/  211 batches    0.129 sec| accuracy    0.988\n",
      "| epoch  10 |   133/  211 batches    0.043 sec| accuracy    1.000\n",
      "| epoch  10 |   136/  211 batches    0.133 sec| accuracy    0.993\n",
      "| epoch  10 |   137/  211 batches    0.043 sec| accuracy    0.996\n",
      "| epoch  10 |   140/  211 batches    0.134 sec| accuracy    0.987\n",
      "| epoch  10 |   141/  211 batches    0.044 sec| accuracy    0.988\n",
      "| epoch  10 |   192/  211 batches    2.200 sec| accuracy    0.988\n",
      "| epoch  10 |   193/  211 batches    0.042 sec| accuracy    0.988\n",
      "| epoch  10 |   196/  211 batches    0.125 sec| accuracy    0.984\n",
      "| epoch  10 |   197/  211 batches    0.042 sec| accuracy    0.988\n",
      "| epoch  10 |   200/  211 batches    0.128 sec| accuracy    0.991\n",
      "| epoch  10 |   201/  211 batches    0.042 sec| accuracy    0.988\n",
      "| epoch  10 |   204/  211 batches    0.129 sec| accuracy    0.991\n",
      "| epoch  10 |   205/  211 batches    0.042 sec| accuracy    0.988\n",
      "------------------------------------------------------------\n",
      "| End of epoch  10 | Time:10.133832216262817s | Train Accuracy    0.989 | Train Loss    0.037 | Valid Accuracy    0.984 | Valid Loss    0.056\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154696/261858771.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lenet_model.load_state_dict(torch.load(save_model + '/lenet_model.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNetClassifier(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
       "  (avgpool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (avgpool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc_1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc_2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc_3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(train_data.dataset.classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "lenet_model = LeNetClassifier(num_classes=num_classes)\n",
    "lenet_model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lenet_model.parameters())\n",
    "\n",
    "num_epochs = 10\n",
    "save_model = './model'\n",
    "if not os.path.exists(save_model):\n",
    "    os.makedirs(save_model)\n",
    "\n",
    "train_accs, train_losses = [], []\n",
    "eval_accs, eval_losses = [], []\n",
    "best_loss_eval = 100\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_acc, train_loss = train(\n",
    "        lenet_model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        train_dataloader,\n",
    "        device,\n",
    "        epoch\n",
    "    )\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    eval_acc, eval_loss = evaluate(\n",
    "        lenet_model,\n",
    "        criterion,\n",
    "        valid_dataloader,\n",
    "        device\n",
    "    )\n",
    "    eval_accs.append(eval_acc)\n",
    "    eval_losses.append(eval_loss)\n",
    "\n",
    "    if eval_loss < best_loss_eval:\n",
    "        torch.save(lenet_model.state_dict(), save_model + '/lenet_model.pt')\n",
    "    \n",
    "    print('-' * 60)\n",
    "    print(\n",
    "        f\"| End of epoch {epoch:3d} | Time:{time.time() - epoch_start_time}s | Train Accuracy {train_acc:8.3f} | Train Loss {train_loss:8.3f} \"\n",
    "        f\"| Valid Accuracy {eval_acc:8.3f} | Valid Loss {eval_loss:8.3f}\"\n",
    "    )\n",
    "    print('-' * 60)\n",
    "\n",
    "lenet_model.load_state_dict(torch.load(save_model + '/lenet_model.pt'))\n",
    "lenet_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9882, 0.038810593219386645)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.transform = test_transforms\n",
    "test_dataloader = data.DataLoader(\n",
    "    test_data,\n",
    "    BATCH_SIZE,\n",
    ")\n",
    "test_acc, test_loss = evaluate(lenet_model, criterion, test_dataloader, device)\n",
    "test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024-hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
