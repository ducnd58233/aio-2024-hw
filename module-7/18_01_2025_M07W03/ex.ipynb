{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tracking: Theo dõi vị trí các đối tượng qua cá khung hình liên tiếp\n",
    "* Counting: Đếm số lượng các đối tượng trong ảnh\n",
    "* Open vocabulary: nhận điện các đối tượng không nằm trong danh sách label cố định"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt to 'yolo11l.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49.0M/49.0M [00:01<00:00, 26.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolo11l.pt')\n",
    "\n",
    "video_path = 'samples/vietnam.mp4'\n",
    "cap = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Create VideoWriter object\n",
    "video_name = video_path.split('/')[-1]\n",
    "output_path = f'./run/{video_name.split('.')[0]}_tracked.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Khởi tạo lịch sử theo dõi và vòng lặp xử lý frames: Chúng ta sẽ sử dụng một defaultdict để lưu trữ lịch sử theo dõi các đối tượng và thực hiện vòng lặp qua từng frame của video để thực hiện việc theo dõi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video has been saved to ./run/vietnam_tracked.mp4\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "track_history = defaultdict(lambda: deque())\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "    results = model.track(frame, persist=True, show=False)\n",
    "    \n",
    "    # Get the boxes and track IDs (with error handling)\n",
    "    boxes = results[0].boxes.xywh.cpu()\n",
    "    try:\n",
    "        track_ids = results[0].boxes.id\n",
    "        if track_ids is not None:\n",
    "            track_ids = track_ids.int().cpu().tolist()\n",
    "        else:\n",
    "            track_ids = [] # No tracks found in this frame\n",
    "    except AttributeError:\n",
    "        track_ids = [] # Handle case where tracking fails\n",
    "    \n",
    "    # Visualize the results on the frame    \n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Plot the tracks only if we have valid tracking data\n",
    "    if track_ids:\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box\n",
    "            track = track_history[track_id]\n",
    "            track.append((float(x), float(y))) # x, y center point\n",
    "            \n",
    "            if len(track) > 120: # retain 30 tracks for 30 frames\n",
    "                track.popleft()\n",
    "                \n",
    "            # Draw the tracking lines\n",
    "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(\n",
    "                annotated_frame,\n",
    "                [points],\n",
    "                isClosed=False,\n",
    "                color=(230, 230, 230),\n",
    "                thickness=4,\n",
    "            )\n",
    "    # Write the frame to output video\n",
    "    out.write(annotated_frame)\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "print(f'Video has been saved to {output_path}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024-hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
