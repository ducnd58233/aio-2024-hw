{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 1->3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "corpus = [\"ai is powerful and useful\",\n",
    "          \"smart and adaptive system\",\n",
    "          \"very smart and useful\",\n",
    "          \"learning AI is very hard\",\n",
    "          \"ai can be biased\",\n",
    "          \"biased and flawed\"]\n",
    "\n",
    "y_data = np.array([1, 1, 1, 0, 0, 0])\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_data = vectorizer.fit_transform(corpus)\n",
    "\n",
    "text = \"ai is a smart system\"\n",
    "X_text = vectorizer.transform([text])\n",
    "X_text.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ai': 1, 'is': 8, 'powerful': 10, 'and': 2, 'useful': 13, 'smart': 11, 'adaptive': 0, 'system': 12, 'very': 14, 'learning': 9, 'hard': 7, 'can': 5, 'be': 3, 'biased': 4, 'flawed': 6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Bộ từ vựng xây dựng từ corpus: {'adaptive': 0, 'ai': 1, 'and': 2, 'be': 3, 'biased': 4, 'can': 5, 'flawed': 6, 'hard': 7, 'is': 8, 'learning': 9, 'powerful': 10, 'smart': 11, 'system': 12, 'useful': 13, 'very': 14}\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_to_idx = vectorizer.vocabulary_\n",
    "print(word_to_idx)\n",
    "display(\n",
    "    f\"Bộ từ vựng xây dựng từ corpus: {dict(sorted(vectorizer.vocabulary_.items()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance: 2.236068\n",
      "Euclidean distance2: 2.236068\n"
     ]
    }
   ],
   "source": [
    "text2 = \"learning AI is very hard\"\n",
    "X_text2 = vectorizer.transform([text2])\n",
    "X_text2.toarray()\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "euclid_dist = np.linalg.norm(X_text.toarray() - X_text2.toarray())\n",
    "euclid_dist2 = euclidean_distance(X_text.toarray(), X_text2.toarray())\n",
    "print(f\"Euclidean distance: {euclid_dist:2f}\")\n",
    "print(f\"Euclidean distance2: {euclid_dist2:2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarities: [0.4472136 0.5       0.25      0.4472136 0.25      0.       ]\n",
      "Top 3 câu tương tự nhất:\n",
      "1. smart and adaptive system\n",
      "2. learning AI is very hard\n",
      "3. ai is powerful and useful\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def top_3_similar_to_text(X_text, X_data, corpus):\n",
    "    # Tính cosine similarity giữa câu query và tất cả câu trong corpus\n",
    "    similarities = cosine_similarity(X_text, X_data)[0]\n",
    "    print(f'similarities: {similarities}')\n",
    "    # Lấy ra 3 index có similarity cao nhất\n",
    "    top_3_indices = similarities.argsort()[-3:][::-1]\n",
    "\n",
    "    # Trả về 3 câu tương ứng từ corpus\n",
    "    return [corpus[i] for i in top_3_indices]\n",
    "\n",
    "\n",
    "X_text = vectorizer.transform([\"ai is a smart system\"])\n",
    "result = top_3_similar_to_text(X_text, X_data, corpus)\n",
    "print(\"Top 3 câu tương tự nhất:\")\n",
    "for i, sentence in enumerate(result, 1):\n",
    "    print(f\"{i}. {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "Distance: 2.6457513110645907\n",
      "[0 0 1 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "Distance: 2.23606797749979\n",
      "[0 1 0 0 0 0 0 1 1 1 0 0 0 0 1]\n",
      "Distance: 2.449489742783178\n",
      "[0 0 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "Distance: 2.449489742783178\n"
     ]
    }
   ],
   "source": [
    "# Q8\n",
    "C1 = [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]  # ai is powerful and useful\n",
    "for i in [1, 2, 3, 5]:\n",
    "    print(X_data.toarray()[i])\n",
    "    dist = np.linalg.norm(C1 - X_data.toarray()[i])\n",
    "    print(f'Distance: {dist}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      "Distance: 2.8284271247461903\n",
      "[0 0 1 0 0 0 0 0 0 0 0 1 0 1 1]\n",
      "Distance: 2.8284271247461903\n",
      "[0 1 0 0 0 0 0 1 1 1 0 0 0 0 1]\n",
      "Distance: 2.6457513110645907\n",
      "[0 0 1 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      "Distance: 2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "# Q9\n",
    "C2 = [0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "for i in [1, 2, 3, 5]:\n",
    "    print(X_data.toarray()[i])\n",
    "    dist = np.linalg.norm(C2 - X_data.toarray()[i])\n",
    "    print(f'Distance: {dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocation: ['C1', 'C1', 'C1', 'C1', 'C2', 'C2']\n"
     ]
    }
   ],
   "source": [
    "# Q10\n",
    "allocation = []\n",
    "\n",
    "for vec in X_data.toarray():\n",
    "    dist1 = np.linalg.norm(C1 - vec)\n",
    "    dist2 = np.linalg.norm(C2 - vec)\n",
    "    if dist1 < dist2:\n",
    "        allocation.append('C1')\n",
    "    else:\n",
    "        allocation.append('C2')\n",
    "\n",
    "print(f'Allocation: {allocation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tọa độ tâm cụm mới C1: [0.25 0.5  0.75 0.   0.   0.   0.   0.25 0.5  0.25 0.25 0.5  0.25 0.5\n",
      " 0.5 ]\n",
      "Tọa độ tâm cụm mới C2: [0.  0.5 0.5 0.5 1.  0.5 0.5 0.  0.  0.  0.  0.  0.  0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "# Q11: Cập nhật lại tọa độ tâm cụm mới của C1 và C2\n",
    "C1_points = []\n",
    "C2_points = []\n",
    "\n",
    "for i in range(len(X_data.toarray())):\n",
    "    if allocation[i] == 'C1':\n",
    "        C1_points.append(X_data.toarray()[i])\n",
    "    else:\n",
    "        C2_points.append(X_data.toarray()[i])\n",
    "        \n",
    "C1_points = np.array(C1_points)\n",
    "C2_points = np.array(C2_points)\n",
    "\n",
    "C1_new = np.mean(C1_points, axis=0) if len(\n",
    "    C1_points) > 0 else np.zeros_like(C1)\n",
    "C2_new = np.mean(C2_points, axis=0) if len(\n",
    "    C2_points) > 0 else np.zeros_like(C2)\n",
    "\n",
    "print(\"Tọa độ tâm cụm mới C1:\", C1_new)\n",
    "print(\"Tọa độ tâm cụm mới C2:\", C2_new)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocation: ['C1', 'C1', 'C1', 'C1', 'C2', 'C2']\n"
     ]
    }
   ],
   "source": [
    "# Q12\n",
    "allocation = []\n",
    "\n",
    "for vec in X_data.toarray():\n",
    "    dist1 = np.linalg.norm(C1_new - vec)\n",
    "    dist2 = np.linalg.norm(C2_new - vec)\n",
    "    if dist1 < dist2:\n",
    "        allocation.append('C1')\n",
    "    else:\n",
    "        allocation.append('C2')\n",
    "\n",
    "print(f'Allocation: {allocation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 4 -> 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\AIVietNam\\2024\\aio-2024-hw\\tests\\final\\23_05_2025_test1\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\AIVietNam\\2024\\aio-2024-hw\\tests\\final\\23_05_2025_test1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1dLF8lffQLgBO5Thu__Lk5Pbw57fTkncc\n",
      "To: d:\\AIVietNam\\2024\\aio-2024-hw\\tests\\final\\23_05_2025_test1\\data\\final_dataset.csv\n",
      "\n",
      "  0%|          | 0.00/220 [00:00<?, ?B/s]\n",
      "100%|██████████| 220/220 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "%cd data\n",
    "\n",
    "!gdown 1dLF8lffQLgBO5Thu__Lk5Pbw57fTkncc\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "[[0.29, 0.18, 0.12], [0.11, 0.06, 0.17], [0.34, 0.21, 0.2], [0.26, 0.15, 0.09], [0.22, 0.09, 0.2], [0.58, 0.42, 0.47], [0.56, 0.37, 0.77], [0.48, 0.38, 0.28], [0.63, 0.49, 0.39], [0.54, 0.42, 0.43]]\n",
      "labels:\n",
      "['B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'M', 'M']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/final_dataset.csv')\n",
    "X_train = df.drop(columns=['diagnosis']).values.tolist()\n",
    "labels = df['diagnosis'].values.tolist()\n",
    "\n",
    "print(f'X_train:\\n{X_train}')\n",
    "print(f'labels:\\n{labels}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train:\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "\n",
    "for label in labels:\n",
    "    if label == 'B':\n",
    "        y_train.append(0)\n",
    "    else:\n",
    "        y_train.append(1)\n",
    "\n",
    "print(f'y_train:\\n{y_train}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.24\n",
      "2: 0.41000000000000003\n",
      "3: 0.18000000000000002\n"
     ]
    }
   ],
   "source": [
    "x = [0.25, 0.25, 0.25]\n",
    "\n",
    "def manhattan_distance(x1, x2):\n",
    "    return sum(abs(a - b) for a, b in zip(x1, x2))\n",
    "\n",
    "for i in range(3):\n",
    "    print(f'{i + 1}: {manhattan_distance(x, X_train[i])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_classes:\n",
      "[5, 2]\n"
     ]
    }
   ],
   "source": [
    "manhattan_distances = [(manhattan_distance(x, X_train[i]), y_train[i]) for i in range(len(X_train))]\n",
    "manhattan_distances.sort(key = lambda x: x[0])\n",
    "\n",
    "count_classes = [0, 0]\n",
    "for i in range(7):\n",
    "    count_classes[manhattan_distances[i][1]] += 1\n",
    "\n",
    "print(f'count_classes:\\n{count_classes}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 0.09899494936611669\n",
      "Distance: 0.2762245463386627\n",
      "Distance: 0.0\n",
      "Distance: 0.14866068747318506\n",
      "Distance: 0.16970562748477142\n",
      "Distance: 0.41785164831552346\n",
      "Distance: 0.6315853069855252\n",
      "Distance: 0.23430749027719963\n",
      "Distance: 0.44564559910314383\n",
      "Distance: 0.37013511046643494\n",
      "Total distance: 2.793110965810563\n"
     ]
    }
   ],
   "source": [
    "# Q13\n",
    "C1 = np.array([0.34, 0.21, 0.2])\n",
    "C2 = np.array([0.63, 0.49, 0.39])\n",
    "\n",
    "total_dist = 0\n",
    "\n",
    "for vec in X_train:\n",
    "    vec = np.array(vec)\n",
    "    dist = np.linalg.norm(C1 - vec)\n",
    "    print(f'Distance: {dist}')\n",
    "    total_dist += dist\n",
    "\n",
    "print(f'Total distance: {total_dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 0.5334791467339656\n",
      "Distance: 0.7097182539571602\n",
      "Distance: 0.44564559910314383\n",
      "Distance: 0.5852349955359812\n",
      "Distance: 0.6034898507845845\n",
      "Distance: 0.1174734012447073\n",
      "Distance: 0.4045985664828782\n",
      "Distance: 0.2161018278497431\n",
      "Distance: 0.0\n",
      "Distance: 0.1208304597359457\n",
      "Total distance: 3.7365721014281092\n"
     ]
    }
   ],
   "source": [
    "# Q14\n",
    "total_dist = 0\n",
    "\n",
    "for vec in X_train:\n",
    "    vec = np.array(vec)\n",
    "    dist = np.linalg.norm(C2 - vec)\n",
    "    print(f'Distance: {dist}')\n",
    "    total_dist += dist\n",
    "\n",
    "print(f'Total distance: {total_dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocation: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Q15\n",
    "allocation = []\n",
    "\n",
    "for vec in X_train:\n",
    "    vec = np.array(vec)\n",
    "    dist1 = np.linalg.norm(C1 - vec)\n",
    "    dist2 = np.linalg.norm(C2 - vec)\n",
    "    if dist1 < dist2:\n",
    "        allocation.append(0)\n",
    "    else:\n",
    "        allocation.append(1)\n",
    "\n",
    "print(f'Allocation: {allocation}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tọa độ tâm cụm mới C1: [0.244 0.138 0.156]\n",
      "Tọa độ tâm cụm mới C2: [0.558 0.416 0.468]\n"
     ]
    }
   ],
   "source": [
    "# Q16\n",
    "C1_points = []\n",
    "C2_points = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if allocation[i] == 0:\n",
    "        C1_points.append(X_train[i])\n",
    "    else:\n",
    "        C2_points.append(X_train[i])\n",
    "\n",
    "C1_points = np.array(C1_points)\n",
    "C2_points = np.array(C2_points)\n",
    "\n",
    "C1_new = np.mean(C1_points, axis=0) if len(\n",
    "    C1_points) > 0 else np.zeros_like(C1)\n",
    "C2_new = np.mean(C2_points, axis=0) if len(\n",
    "    C2_points) > 0 else np.zeros_like(C2)\n",
    "\n",
    "print(\"Tọa độ tâm cụm mới C1:\", C1_new)\n",
    "print(\"Tọa độ tâm cụm mới C2:\", C2_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocation: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Q17\n",
    "allocation = []\n",
    "\n",
    "for vec in X_train:\n",
    "    vec = np.array(vec)\n",
    "    dist1 = np.linalg.norm(C1_new - vec)\n",
    "    dist2 = np.linalg.norm(C2_new - vec)\n",
    "    if dist1 < dist2:\n",
    "        allocation.append(0)\n",
    "    else:\n",
    "        allocation.append(1)\n",
    "\n",
    "print(f'Allocation: {allocation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 18 ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook Temperature Humidity    Wind PlayTennis\n",
      "0     Sunny        Cool     High    Weak        Yes\n",
      "1     Sunny        Cool     High  Strong         No\n",
      "2  Overcast        Mild     High    Weak        Yes\n",
      "3      Rain         Hot   Normal    Weak        Yes\n",
      "4      Rain         Hot   Normal  Strong         No\n",
      "5  Overcast         Hot   Normal  Strong        Yes\n",
      "6     Sunny        Mild     High    Weak         No\n",
      "7     Sunny        Cool   Normal    Weak        Yes\n",
      "8     Sunny         Hot     High    Weak         No\n",
      "9      Rain        Cool   Normal    Weak        Yes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "    Outlook Temperature Humidity    Wind PlayTennis\n",
      "0     Sunny        Cool   Normal  Strong        Yes\n",
      "1  Overcast         Hot     High  Strong        Yes\n",
      "2  Overcast        Mild   Normal    Weak        Yes\n",
      "3      Rain        Cool     High  Strong         No\n"
     ]
    }
   ],
   "source": [
    "train_data = {\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Sunny', 'Rain'],\n",
    "    'Temperature': ['Cool', 'Cool', 'Mild', 'Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Hot', 'Cool'],\n",
    "    'Humidity': ['High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High', 'Normal'],\n",
    "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Weak'],\n",
    "    'PlayTennis': ['Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    'Outlook': ['Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
    "    'Temperature': ['Cool', 'Hot', 'Mild', 'Cool'],\n",
    "    'Humidity': ['Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['Strong', 'Strong', 'Weak', 'Strong'],\n",
    "    'PlayTennis': ['Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "df_train = pd.DataFrame(train_data)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "print(df_train)\n",
    "print('-'*100)\n",
    "print(df_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "# Q18\n",
    "def calculate_entropy(df):\n",
    "    unique_classes, counts = np.unique(df['PlayTennis'], return_counts=True)\n",
    "    probabilities = counts / len(df)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "print(calculate_entropy(df_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0464393446710154\n"
     ]
    }
   ],
   "source": [
    "# Q19\n",
    "def calculate_information_gain(df, attribute):\n",
    "    unique_values = np.unique(df[attribute])\n",
    "    total_entropy = calculate_entropy(df)\n",
    "    weighted_entropy = 0\n",
    "    total_samples = len(df)\n",
    "    \n",
    "    for value in unique_values:\n",
    "        subset = df[df[attribute] == value]\n",
    "        weighted_entropy += len(subset) / total_samples * calculate_entropy(subset)\n",
    "        \n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "print(calculate_information_gain(df_train, 'Temperature'))\n",
    "\n",
    "\n",
    "# Q20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain của Outlook: 0.2099865470109874\n",
      "Information Gain của Temperature: 0.0464393446710154\n",
      "Information Gain của Humidity: 0.12451124978365313\n",
      "Information Gain của Wind: 0.0912774462416801\n",
      "\n",
      "Thuộc tính tốt nhất để chia nhánh đầu tiên là Outlook với Information Gain = 0.2099865470109874\n"
     ]
    }
   ],
   "source": [
    "# Q20\n",
    "def find_best_split_feature(data, features):\n",
    "    gains = {}\n",
    "    for feature in features:\n",
    "        gain = calculate_information_gain(data, feature)\n",
    "        gains[feature] = gain\n",
    "        print(f\"Information Gain của {feature}: {gain}\")\n",
    "\n",
    "    # Tìm thuộc tính có gain cao nhất\n",
    "    best_feature = max(gains.items(), key=lambda x: x[1])\n",
    "    return best_feature\n",
    "\n",
    "\n",
    "# Các thuộc tính cần xem xét\n",
    "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "\n",
    "# Tìm thuộc tính tốt nhất để split\n",
    "best_feature = find_best_split_feature(df_train, features)\n",
    "print(\n",
    "    f\"\\nThuộc tính tốt nhất để chia nhánh đầu tiên là {best_feature[0]} với Information Gain = {best_feature[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lá trong cây quyết định: 7\n"
     ]
    }
   ],
   "source": [
    "def build_decision_tree(data, features, parent_entropy=None, depth=0):\n",
    "    # Nếu tất cả các mẫu thuộc cùng một class\n",
    "    if len(data['PlayTennis'].unique()) == 1:\n",
    "        return {'leaf': True, 'class': data['PlayTennis'].iloc[0]}\n",
    "\n",
    "    # Nếu không còn feature nào để split\n",
    "    if len(features) == 0:\n",
    "        majority_class = data['PlayTennis'].mode()[0]\n",
    "        return {'leaf': True, 'class': majority_class}\n",
    "\n",
    "    # Tìm feature tốt nhất để split\n",
    "    best_gain = -1\n",
    "    best_feature = None\n",
    "\n",
    "    for feature in features:\n",
    "        gain = calculate_information_gain(data, feature)\n",
    "        if gain > best_gain:\n",
    "            best_gain = gain\n",
    "            best_feature = feature\n",
    "\n",
    "    tree = {'feature': best_feature, 'children': {}}\n",
    "    remaining_features = [f for f in features if f != best_feature]\n",
    "\n",
    "    # Chia nhánh theo các giá trị của feature tốt nhất\n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        if len(subset) == 0:\n",
    "            tree['children'][value] = {'leaf': True, 'class': data['PlayTennis'].mode()[\n",
    "                0]}\n",
    "        else:\n",
    "            tree['children'][value] = build_decision_tree(\n",
    "                subset, remaining_features, depth=depth+1)\n",
    "\n",
    "    return tree\n",
    "\n",
    "\n",
    "features = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
    "decision_tree = build_decision_tree(df_train, features)\n",
    "\n",
    "\n",
    "def count_leaves(tree):\n",
    "    if tree.get('leaf', False):\n",
    "        return 1\n",
    "    return sum(count_leaves(child) for child in tree['children'].values())\n",
    "\n",
    "\n",
    "num_leaves = count_leaves(decision_tree)\n",
    "print(f\"Số lá trong cây quyết định: {num_leaves}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kết quả dự đoán toàn bộ tập test:\n",
      "Mẫu 1: Dự đoán = No, Thực tế = Yes\n",
      "Mẫu 2: Dự đoán = Yes, Thực tế = Yes\n",
      "Mẫu 3: Dự đoán = Yes, Thực tế = Yes\n",
      "Mẫu 4: Dự đoán = No, Thực tế = No\n"
     ]
    }
   ],
   "source": [
    "# Q22\n",
    "\n",
    "def predict_single(tree, sample):\n",
    "    \"\"\"\n",
    "    Dự đoán một mẫu dữ liệu dựa trên cây quyết định\n",
    "    \n",
    "    Args:\n",
    "        tree: Cây quyết định đã xây dựng\n",
    "        sample: Dictionary chứa các feature của mẫu cần dự đoán\n",
    "    \n",
    "    Returns:\n",
    "        Kết quả dự đoán (Yes/No)\n",
    "    \"\"\"\n",
    "    # Nếu là node lá, trả về class\n",
    "    if tree.get('leaf', False):\n",
    "        return tree['class']\n",
    "\n",
    "    # Lấy giá trị của feature tại node hiện tại\n",
    "    feature = tree['feature']\n",
    "    value = sample[feature]\n",
    "\n",
    "    # Nếu giá trị không có trong cây (không xuất hiện trong tập train)\n",
    "    if value not in tree['children']:\n",
    "        # Trả về giá trị phổ biến nhất trong node cha\n",
    "        return max(tree['children'].items(), key=lambda x: len(x[1]))[1]['class']\n",
    "\n",
    "    # Đệ quy xuống nhánh tương ứng\n",
    "    return predict_single(tree['children'][value], sample)\n",
    "\n",
    "\n",
    "def predict_all(tree, test_data):\n",
    "    \"\"\"\n",
    "    Dự đoán cho toàn bộ tập test\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for i in range(len(test_data)):\n",
    "        sample = {\n",
    "            'Outlook': test_data['Outlook'][i],\n",
    "            'Temperature': test_data['Temperature'][i],\n",
    "            'Humidity': test_data['Humidity'][i],\n",
    "            'Wind': test_data['Wind'][i]\n",
    "        }\n",
    "        predictions.append(predict_single(tree, sample))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Dự đoán toàn bộ tập test\n",
    "all_predictions = predict_all(decision_tree, df_test)\n",
    "print(\"\\nKết quả dự đoán toàn bộ tập test:\")\n",
    "for i, (pred, actual) in enumerate(zip(all_predictions, df_test['PlayTennis'])):\n",
    "    print(f\"Mẫu {i+1}: Dự đoán = {pred}, Thực tế = {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "# Q23\n",
    "\n",
    "test_sample = {\n",
    "    'Outlook': 'Overcast',\n",
    "    'Wind': 'Weak'\n",
    "}\n",
    "\n",
    "print(predict_single(decision_tree, test_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Wind'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Q24\u001b[39;00m\n\u001b[32m      3\u001b[39m test_sample = {\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTemperature\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mHot\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mOutlook\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mRain\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_sample\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mpredict_single\u001b[39m\u001b[34m(tree, sample)\u001b[39m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(tree[\u001b[33m'\u001b[39m\u001b[33mchildren\u001b[39m\u001b[33m'\u001b[39m].items(), key=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x[\u001b[32m1\u001b[39m]))[\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Đệ quy xuống nhánh tương ứng\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mchildren\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mpredict_single\u001b[39m\u001b[34m(tree, sample)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Lấy giá trị của feature tại node hiện tại\u001b[39;00m\n\u001b[32m     19\u001b[39m feature = tree[\u001b[33m'\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m value = \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Nếu giá trị không có trong cây (không xuất hiện trong tập train)\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tree[\u001b[33m'\u001b[39m\u001b[33mchildren\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Trả về giá trị phổ biến nhất trong node cha\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'Wind'"
     ]
    }
   ],
   "source": [
    "# Q24\n",
    "\n",
    "test_sample = {\n",
    "    'Temperature': 'Hot',\n",
    "    'Outlook': 'Rain'\n",
    "}\n",
    "\n",
    "print(predict_single(decision_tree, test_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi tiết dự đoán:\n",
      "Mẫu 1: Dự đoán = No, Thực tế = Yes\n",
      "Mẫu 2: Dự đoán = Yes, Thực tế = Yes\n",
      "Mẫu 3: Dự đoán = Yes, Thực tế = Yes\n",
      "Mẫu 4: Dự đoán = No, Thực tế = No\n",
      "\n",
      "Độ chính xác trên tập kiểm tra: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Q24\n",
    "\n",
    "def calculate_accuracy(predictions, actual):\n",
    "    \"\"\"\n",
    "    Tính độ chính xác của mô hình\n",
    "    \n",
    "    Args:\n",
    "        predictions: List các dự đoán\n",
    "        actual: List các giá trị thực tế\n",
    "    \n",
    "    Returns:\n",
    "        Độ chính xác (tỷ lệ dự đoán đúng)\n",
    "    \"\"\"\n",
    "    correct = sum(1 for p, a in zip(predictions, actual) if p == a)\n",
    "    return correct / len(actual)\n",
    "\n",
    "\n",
    "# Dự đoán toàn bộ tập test\n",
    "predictions = predict_all(decision_tree, df_test)\n",
    "actual = df_test['PlayTennis'].tolist()\n",
    "\n",
    "# In kết quả chi tiết\n",
    "print(\"Chi tiết dự đoán:\")\n",
    "for i, (pred, act) in enumerate(zip(predictions, actual), 1):\n",
    "    print(f\"Mẫu {i}: Dự đoán = {pred}, Thực tế = {act}\")\n",
    "\n",
    "# Tính và in độ chính xác\n",
    "accuracy = calculate_accuracy(predictions, actual)\n",
    "print(f\"\\nĐộ chính xác trên tập kiểm tra: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q27\n",
    "\n",
    "Ý nghĩa khi Information Gain = 0:\n",
    "- Entropy trước và sau khi split là như nhau\n",
    "- Việc phân chia theo thuộc tính này không giảm độ không chắc chắn\n",
    "- Phân phối các class trong các nhánh con giống với phân phối ban đầu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q28 Khi so sánh với các kỹ thuật ensemble như Gradient Boosting, một lợi thế nổi bật của Random Forest, đặc biệt khi làm việc với tập dữ liệu lớn, là gì?\n",
    "Việc huấn luyện các cây trong Random Forest có thể được thực hiện song song một cách hiệu quả do tính độc lập của chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024-hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
