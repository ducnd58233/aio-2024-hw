{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    [23, 0, 0, 0],\n",
    "    [25, 1, 1, 0],\n",
    "    [27, 1, 0, 1],\n",
    "    [29, 0, 1, 1],\n",
    "    [29, 0, 0, 0]\n",
    "]\n",
    "df = pd.DataFrame(data, columns=[\"Age\", \"Likes English\", \"Likes AI\", \"Raise Salary\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise_salary_col = df[\"Raise Salary\"]\n",
    "raise_salary_col = np.array(raise_salary_col)\n",
    "\n",
    "def gini_impurity(labels):\n",
    "\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    probabilities = counts / len(labels)\n",
    "    \n",
    "    gini = 1 - np.sum(np.square(probabilities))\n",
    "    \n",
    "    return gini\n",
    "\n",
    "gini_raise_salary = gini_impurity(raise_salary_col)\n",
    "print(gini_raise_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity_split(feature, labels, condition):\n",
    "    D1 = labels[feature <= condition]\n",
    "    D2 = labels[feature > condition]\n",
    "    \n",
    "    total_instances = len(labels)\n",
    "    len_D1 = len(D1)\n",
    "    len_D2 = len(D2)\n",
    "    \n",
    "    gini_D1 = gini_impurity(D1)\n",
    "    gini_D2 = gini_impurity(D2)\n",
    "    \n",
    "    weight_gini = (len_D1 / total_instances) * gini_D1 + (len_D2 / total_instances) * gini_D2\n",
    "    \n",
    "    return weight_gini\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_english_col = np.array(df[\"Likes English\"])\n",
    "raise_salary_col = np.array(df[\"Raise Salary\"])\n",
    "\n",
    "gini_likes_english_split = gini_impurity_split(likes_english_col, raise_salary_col, 0)\n",
    "print(gini_likes_english_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = np.array(df[\"Age\"])\n",
    "raise_salary_col = np.array(df[\"Raise Salary\"])\n",
    "\n",
    "\n",
    "gini_age_split = gini_impurity_split(age_col, raise_salary_col, 26)\n",
    "print(gini_age_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    probabilities = counts / len(labels)\n",
    "    \n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise_salary_col = np.array(df[\"Raise Salary\"])\n",
    "\n",
    "entropy_raise_salary = entropy(raise_salary_col)\n",
    "print(entropy_raise_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(feature, labels, condition):\n",
    "    initial_entropy = entropy(labels)\n",
    "    D1 = labels[feature <= condition]\n",
    "    D2 = labels[feature > condition]\n",
    "    \n",
    "    total_instances = len(labels)\n",
    "    len_D1 = len(D1)\n",
    "    len_D2 = len(D2)\n",
    "    \n",
    "    entropy_D1 = entropy(D1)\n",
    "    entropy_D2 = entropy(D2)\n",
    "    \n",
    "    weighted_entropy = (len_D1 / total_instances) * entropy_D1 + (len_D2 / total_instances) * entropy_D2\n",
    "    gain = initial_entropy - weighted_entropy\n",
    "    return gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_english_col = np.array(df[\"Likes English\"])\n",
    "raise_salary_col = np.array(df[\"Raise Salary\"])\n",
    "\n",
    "entropy_likes_english = information_gain(likes_english_col, raise_salary_col, 0)\n",
    "print(entropy_likes_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "iris_x, iris_y = datasets.load_iris(return_X_y= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris_x, iris_y = datasets.load_iris(return_X_y= True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    iris_x, iris_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "dt_classifier.fit(x_train,y_train)\n",
    "\n",
    "y_pred = dt_classifier.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regression = [\n",
    "    [23, 0, 0, 299],\n",
    "    [25, 1, 1, 400],\n",
    "    [27, 1, 0, 300],\n",
    "    [29, 0, 1, 500],\n",
    "    [29, 0, 0, 400]\n",
    "]\n",
    "df_regression = pd.DataFrame(data_regression, columns=[\"Age\", \"Likes English\", \"Likes AI\", \"Salary\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_squared_error(feature, labels, condition):\n",
    "    D1 = labels[feature <= condition]\n",
    "    D2 = labels[feature > condition]\n",
    "    \n",
    "    mean_D1 = np.mean(D1)\n",
    "    mean_D2 = np.mean(D2)\n",
    "    \n",
    "    sse_D1 = np.sum((D1 - mean_D1) ** 2)\n",
    "    sse_D2 = np.sum((D2 - mean_D2) ** 2)\n",
    "    \n",
    "    total_sse = sse_D1 + sse_D2\n",
    "    \n",
    "    return total_sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_ai_col = np.array(df_regression[\"Likes AI\"])\n",
    "raise_salary_col = np.array(df_regression[\"Salary\"])\n",
    "print(raise_salary_col)\n",
    "\n",
    "sse_likes_ai = sum_squared_error(likes_ai_col, raise_salary_col, 0)\n",
    "print(sse_likes_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_col = np.array(df_regression[\"Age\"])\n",
    "raise_salary_col = np.array(df_regression[\"Salary\"])\n",
    "\n",
    "\n",
    "sse_age_24 = sum_squared_error(age_col, raise_salary_col, 24)\n",
    "print(sse_age_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "machine_cpu = fetch_openml(name='machine_cpu')\n",
    "machine_data = machine_cpu.data\n",
    "machine_labels = machine_cpu.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    machine_data, machine_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "tree_reg.fit(x_train,y_train)\n",
    "\n",
    "y_pred = tree_reg.predict(x_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aio2024-hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
